{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  DENGELI Ã–RNEKLEME: RF vs XGBoost\n"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "mount",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de721592-37f3-43c5-a0b2-803663a63761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/SA_CropType_SourceCoop\")\n",
        "OUT_DIR = BASE_DIR / \"outputs\"\n",
        "META_DIR = OUT_DIR / \"meta\"\n",
        "FIG_DIR = OUT_DIR / \"figures\"\n",
        "TAB_DIR = OUT_DIR / \"tables\"\n",
        "\n",
        "for d in [OUT_DIR, META_DIR, FIG_DIR, TAB_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "!pip install xgboost -q\n",
        "import xgboost as xgb\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"âœ… Kurulum tamam!\")"
      ],
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b3012-0d04-4b8f-ec0a-73208f7564fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Kurulum tamam!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Ã–NCEKÄ° VERÄ°YÄ° YÃœKLE (100 tile sonuÃ§larÄ±)"
      ],
      "metadata": {
        "id": "load_previous"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–nceki notebook'tan oluÅŸan veriyi yÃ¼kle\n",
        "# NOT: EÄŸer 100 tile notebook'u Ã§alÄ±ÅŸtÄ±rmadÄ±ysanÄ±z, Ã¶nce onu Ã§alÄ±ÅŸtÄ±rÄ±n!\n",
        "\n",
        "print(\"ğŸ“‚ Ã–nceki veri aranÄ±yor...\\n\")\n",
        "\n",
        "# Dataset info\n",
        "info_path = TAB_DIR / 'dataset_info_100tiles.json'\n",
        "if info_path.exists():\n",
        "    with open(info_path, 'r') as f:\n",
        "        prev_info = json.load(f)\n",
        "\n",
        "    print(\"âœ… Ã–nceki veri bulundu!\")\n",
        "    print(f\"\\nğŸ“Š Ã–NCEKÄ° SONUÃ‡LAR (100 tile):\")\n",
        "    print(f\"  Toplam Ã¶rnek: {prev_info['total_samples']:,}\")\n",
        "    print(f\"  Ã–zellik sayÄ±sÄ±: {prev_info['n_features']}\")\n",
        "    print(f\"  Dengesizlik: {prev_info['imbalance_ratio']:.2f}x\")\n",
        "    print(f\"\\n  SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
        "    for crop, count in prev_info['class_distribution'].items():\n",
        "        pct = count / prev_info['total_samples'] * 100\n",
        "        print(f\"    {crop:30s}: {count:5,} ({pct:5.1f}%)\")\n",
        "else:\n",
        "    print(\"âš ï¸ Ã–nceki veri bulunamadÄ±!\")\n",
        "    print(\"   Ã–nce 10_OPTIMIZED_100tiles_15dates.ipynb Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
        "    print(\"\\n   Åimdilik varsayÄ±lan deÄŸerlerle devam ediyoruz...\")\n",
        "    prev_info = None"
      ],
      "metadata": {
        "id": "load_prev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434ba60d-e6b3-4554-f9f3-ed1205187477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Ã–nceki veri aranÄ±yor...\n",
            "\n",
            "âœ… Ã–nceki veri bulundu!\n",
            "\n",
            "ğŸ“Š Ã–NCEKÄ° SONUÃ‡LAR (100 tile):\n",
            "  Toplam Ã¶rnek: 8,228\n",
            "  Ã–zellik sayÄ±sÄ±: 22\n",
            "  Dengesizlik: 4.61x\n",
            "\n",
            "  SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\n",
            "    Lucerne/Medics                : 1,043 ( 12.7%)\n",
            "    Planted pastures (perennial)  : 1,326 ( 16.1%)\n",
            "    Wheat                         : 1,050 ( 12.8%)\n",
            "    Wine grapes                   : 4,809 ( 58.4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  DENGELI Ã–RNEKLEME"
      ],
      "metadata": {
        "id": "balanced"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"âš–ï¸ Dengeli Ã¶rnekleme baÅŸlÄ±yor...\\n\")\n",
        "\n",
        "# TFC yÃ¼kle\n",
        "tfc_selected = pd.read_csv(META_DIR / \"tfc_selected_top100.csv\")\n",
        "\n",
        "TARGET_CROPS = [\n",
        "    \"Wine grapes\",\n",
        "    \"Wheat\",\n",
        "    \"Planted pastures (perennial)\",\n",
        "    \"Lucerne/Medics\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ“Š MEVCUT DAÄILIM:\")\n",
        "print(\"=\"*60)\n",
        "for crop in TARGET_CROPS:\n",
        "    count = len(tfc_selected[tfc_selected['crop'] == crop])\n",
        "    print(f\"  {crop:30s}: {count:5,}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# En az Ã¶rnek sayÄ±sÄ±nÄ± bul\n",
        "min_samples = tfc_selected['crop'].value_counts().min()\n",
        "print(f\"\\nğŸ“Œ En az Ã¶rnek: {min_samples:,}\\n\")\n",
        "\n",
        "# DENGELI Ã–RNEKLEME STRATEJÄ°SÄ°\n",
        "# SeÃ§enek 1: Min sample (en az Ã¶rneÄŸi olan sÄ±nÄ±fÄ±n sayÄ±sÄ±)\n",
        "# SeÃ§enek 2: Sabit sayÄ± (Ã¶rn: 1000)\n",
        "\n",
        "# Her sÄ±nÄ±ftan en fazla kaÃ§ tane alabiliriz?\n",
        "max_possible = min_samples\n",
        "\n",
        "# Hedef: 1000 (eÄŸer yeterli veri varsa)\n",
        "TARGET_PER_CLASS = min(1000, max_possible)\n",
        "\n",
        "print(f\"ğŸ¯ HEDEF: Her sÄ±nÄ±ftan {TARGET_PER_CLASS:,} Ã¶rnek\\n\")\n",
        "\n",
        "# Her sÄ±nÄ±ftan rastgele Ã¶rnekle\n",
        "balanced_samples = []\n",
        "\n",
        "for crop in TARGET_CROPS:\n",
        "    crop_data = tfc_selected[tfc_selected['crop'] == crop]\n",
        "\n",
        "    if len(crop_data) >= TARGET_PER_CLASS:\n",
        "        # Rastgele Ã¶rnekle\n",
        "        sampled = crop_data.sample(n=TARGET_PER_CLASS, random_state=42)\n",
        "        balanced_samples.append(sampled)\n",
        "        print(f\"  âœ… {crop:30s}: {len(sampled):,} Ã¶rnek seÃ§ildi\")\n",
        "    else:\n",
        "        # Hepsini al (yeterli deÄŸilse)\n",
        "        balanced_samples.append(crop_data)\n",
        "        print(f\"  âš ï¸ {crop:30s}: {len(crop_data):,} Ã¶rnek (hepsi alÄ±ndÄ±)\")\n",
        "\n",
        "# BirleÅŸtir\n",
        "balanced_tfc = pd.concat(balanced_samples, ignore_index=True)\n",
        "\n",
        "# KarÄ±ÅŸtÄ±r\n",
        "balanced_tfc = balanced_tfc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ… DENGELI VERÄ° SETÄ° OLUÅTURULDU!\")\n",
        "print(f\"  Toplam: {len(balanced_tfc):,} Ã¶rnek\")\n",
        "print(f\"  Her sÄ±nÄ±f: ~{TARGET_PER_CLASS:,} Ã¶rnek\")\n",
        "\n",
        "print(f\"\\nğŸ“Š YENÄ° DAÄILIM:\")\n",
        "print(\"=\"*60)\n",
        "for crop in TARGET_CROPS:\n",
        "    count = len(balanced_tfc[balanced_tfc['crop'] == crop])\n",
        "    pct = count / len(balanced_tfc) * 100\n",
        "    print(f\"  {crop:30s}: {count:5,} ({pct:5.1f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Dengelilik oranÄ±\n",
        "counts = balanced_tfc['crop'].value_counts()\n",
        "imbalance = counts.max() / counts.min()\n",
        "print(f\"\\nâš–ï¸ Dengelilik oranÄ±: {imbalance:.2f}x\")\n",
        "\n",
        "if imbalance < 1.2:\n",
        "    print(\"   âœ… MÃœKEMMEL DENGE!\")\n",
        "elif imbalance < 2:\n",
        "    print(\"   âœ… Ä°YÄ° DENGE\")\n",
        "else:\n",
        "    print(\"   âš ï¸ Hala dengesiz\")\n",
        "\n",
        "# Kaydet\n",
        "balanced_tfc.to_csv(META_DIR / \"tfc_balanced_1000_per_class.csv\", index=False)\n",
        "print(f\"\\nğŸ’¾ Kaydedildi: tfc_balanced_1000_per_class.csv\")"
      ],
      "metadata": {
        "id": "balanced_sampling",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b29f667-feb2-48ab-8118-d1a566b87b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš–ï¸ Dengeli Ã¶rnekleme baÅŸlÄ±yor...\n",
            "\n",
            "ğŸ“Š MEVCUT DAÄILIM:\n",
            "============================================================\n",
            "  Wine grapes                   : 4,809\n",
            "  Wheat                         : 1,050\n",
            "  Planted pastures (perennial)  : 1,326\n",
            "  Lucerne/Medics                : 1,043\n",
            "============================================================\n",
            "\n",
            "ğŸ“Œ En az Ã¶rnek: 1,043\n",
            "\n",
            "ğŸ¯ HEDEF: Her sÄ±nÄ±ftan 1,000 Ã¶rnek\n",
            "\n",
            "  âœ… Wine grapes                   : 1,000 Ã¶rnek seÃ§ildi\n",
            "  âœ… Wheat                         : 1,000 Ã¶rnek seÃ§ildi\n",
            "  âœ… Planted pastures (perennial)  : 1,000 Ã¶rnek seÃ§ildi\n",
            "  âœ… Lucerne/Medics                : 1,000 Ã¶rnek seÃ§ildi\n",
            "\n",
            "âœ… DENGELI VERÄ° SETÄ° OLUÅTURULDU!\n",
            "  Toplam: 4,000 Ã¶rnek\n",
            "  Her sÄ±nÄ±f: ~1,000 Ã¶rnek\n",
            "\n",
            "ğŸ“Š YENÄ° DAÄILIM:\n",
            "============================================================\n",
            "  Wine grapes                   : 1,000 ( 25.0%)\n",
            "  Wheat                         : 1,000 ( 25.0%)\n",
            "  Planted pastures (perennial)  : 1,000 ( 25.0%)\n",
            "  Lucerne/Medics                : 1,000 ( 25.0%)\n",
            "============================================================\n",
            "\n",
            "âš–ï¸ Dengelilik oranÄ±: 1.00x\n",
            "   âœ… MÃœKEMMEL DENGE!\n",
            "\n",
            "ğŸ’¾ Kaydedildi: tfc_balanced_1000_per_class.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Ã–ZELLÄ°K Ã‡IKARIMI (Dengeli Veri)"
      ],
      "metadata": {
        "id": "features"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "\n",
        "TRAIN_DIR = BASE_DIR / \"train\"\n",
        "LABELS_DIR = TRAIN_DIR / \"labels\"\n",
        "S2_DIR = TRAIN_DIR / \"imagery\" / \"s2\"\n",
        "\n",
        "def smart_date_selection(tile_dir, max_dates=15):\n",
        "    \"\"\"AkÄ±llÄ± tarih seÃ§imi (aylara daÄŸÄ±tÄ±lmÄ±ÅŸ)\"\"\"\n",
        "    all_dates = sorted([d for d in tile_dir.iterdir() if d.is_dir()])\n",
        "    if len(all_dates) == 0:\n",
        "        return [], {}\n",
        "\n",
        "    date_info = []\n",
        "    for date_folder in all_dates:\n",
        "        try:\n",
        "            parts = date_folder.name.split('_')\n",
        "            if len(parts) >= 3:\n",
        "                year = int(parts[0])\n",
        "                month = int(parts[1])\n",
        "                date_info.append({\n",
        "                    'path': date_folder,\n",
        "                    'year_month': f\"{year}_{month:02d}\"\n",
        "                })\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if len(date_info) == 0:\n",
        "        return all_dates[:max_dates], {}\n",
        "\n",
        "    df = pd.DataFrame(date_info)\n",
        "    monthly_counts = df.groupby('year_month').size()\n",
        "    n_months = len(monthly_counts)\n",
        "    dates_per_month = max(1, max_dates // n_months)\n",
        "\n",
        "    selected_dates = []\n",
        "    for year_month, group in df.groupby('year_month'):\n",
        "        n_select = min(dates_per_month, len(group))\n",
        "        if len(group) > n_select:\n",
        "            indices = np.linspace(0, len(group)-1, n_select, dtype=int)\n",
        "            selected = group.iloc[indices]\n",
        "        else:\n",
        "            selected = group\n",
        "        selected_dates.extend(selected['path'].tolist())\n",
        "\n",
        "    if len(selected_dates) < max_dates:\n",
        "        remaining = max_dates - len(selected_dates)\n",
        "        for year_month in monthly_counts.nlargest(remaining).index:\n",
        "            group = df[df['year_month'] == year_month]\n",
        "            unselected = [p for p in group['path'] if p not in selected_dates]\n",
        "            if unselected:\n",
        "                selected_dates.append(unselected[0])\n",
        "                if len(selected_dates) >= max_dates:\n",
        "                    break\n",
        "\n",
        "    selected_dates = sorted(selected_dates, key=lambda x: x.name)[:max_dates]\n",
        "    selected_df = df[df['path'].isin(selected_dates)]\n",
        "    distribution = selected_df.groupby('year_month').size().to_dict()\n",
        "\n",
        "    return selected_dates, distribution\n",
        "\n",
        "def extract_features(tile_id, field_id, s2_dir, labels_dir, num_dates=15):\n",
        "    \"\"\"Ã–zellik Ã§Ä±karÄ±mÄ± (akÄ±llÄ± tarih seÃ§imi ile)\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    try:\n",
        "        label_path = labels_dir / f\"{tile_id}_field_ids.tif\"\n",
        "        if not label_path.exists():\n",
        "            return None\n",
        "\n",
        "        with rasterio.open(label_path) as src:\n",
        "            label_mask = src.read(1)\n",
        "\n",
        "        field_mask = (label_mask == field_id)\n",
        "        if field_mask.sum() == 0:\n",
        "            return None\n",
        "\n",
        "        tile_dir = s2_dir / str(tile_id)\n",
        "        if not tile_dir.exists():\n",
        "            return None\n",
        "\n",
        "        date_folders, _ = smart_date_selection(tile_dir, max_dates=num_dates)\n",
        "        if len(date_folders) == 0:\n",
        "            return None\n",
        "\n",
        "        band_map = {'B2': 'B02', 'B3': 'B03', 'B4': 'B04', 'B8': 'B08'}\n",
        "        band_values = {name: [] for name in band_map.keys()}\n",
        "\n",
        "        for date_folder in date_folders:\n",
        "            date_str = date_folder.name\n",
        "            for band_short, band_full in band_map.items():\n",
        "                band_file = date_folder / f\"{tile_id}_{date_str}_{band_full}_10m.tif\"\n",
        "                if band_file.exists():\n",
        "                    with rasterio.open(band_file) as src:\n",
        "                        band_data = src.read(1)\n",
        "                    field_vals = band_data[field_mask]\n",
        "                    field_vals = field_vals[field_vals > 0]\n",
        "                    if len(field_vals) > field_mask.sum() * 0.3:\n",
        "                        band_values[band_short].extend(field_vals.tolist())\n",
        "\n",
        "        for band, vals in band_values.items():\n",
        "            if len(vals) > 0:\n",
        "                features[f'{band}_mean'] = np.mean(vals)\n",
        "                features[f'{band}_std'] = np.std(vals)\n",
        "                features[f'{band}_min'] = np.min(vals)\n",
        "                features[f'{band}_max'] = np.max(vals)\n",
        "                features[f'{band}_median'] = np.median(vals)\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        if 'B8_mean' in features and 'B4_mean' in features:\n",
        "            nir = features['B8_mean']\n",
        "            red = features['B4_mean']\n",
        "            features['NDVI'] = (nir - red) / (nir + red) if (nir + red) > 0 else 0\n",
        "\n",
        "        if all(k in features for k in ['B8_mean', 'B4_mean', 'B2_mean']):\n",
        "            nir = features['B8_mean']\n",
        "            red = features['B4_mean']\n",
        "            blue = features['B2_mean']\n",
        "            denom = nir + 6*red - 7.5*blue + 1\n",
        "            features['EVI'] = 2.5 * (nir - red) / denom if denom != 0 else 0\n",
        "\n",
        "        return features\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "print(\"âœ… Ã–zellik fonksiyonlarÄ± hazÄ±r!\")"
      ],
      "metadata": {
        "id": "feature_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3317e2b3-c2d4-41ec-8366-e4b459257179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ã–zellik fonksiyonlarÄ± hazÄ±r!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ğŸš€ Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor (DENGELI VERÄ°)...\")\n",
        "print(f\"ğŸ“Š Ä°ÅŸlenecek: {len(balanced_tfc):,} kayÄ±t\")\n",
        "print(f\"â±ï¸  Tahmini sÃ¼re: ~{len(balanced_tfc)//200} dakika\\n\")\n",
        "\n",
        "features_list = []\n",
        "labels_list = []\n",
        "failed = 0\n",
        "\n",
        "for idx, row in tqdm(balanced_tfc.iterrows(), total=len(balanced_tfc), desc=\"Ã‡Ä±karÄ±m\"):\n",
        "    tile_id = row['tile_id']\n",
        "    field_id = row['field_id']\n",
        "    crop = row['crop']\n",
        "\n",
        "    feats = extract_features(tile_id, field_id, S2_DIR, LABELS_DIR, num_dates=15)\n",
        "\n",
        "    if feats and len(feats) > 0:\n",
        "        features_list.append(feats)\n",
        "        labels_list.append(crop)\n",
        "    else:\n",
        "        failed += 1\n",
        "\n",
        "print(f\"\\nâœ… TamamlandÄ±!\")\n",
        "print(f\"  BaÅŸarÄ±lÄ±: {len(features_list):,}\")\n",
        "print(f\"  BaÅŸarÄ±sÄ±z: {failed}\")\n",
        "print(f\"  BaÅŸarÄ± oranÄ±: {len(features_list)/(len(features_list)+failed)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "extract",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dda00b4-cf63-40dd-f403-ffe82836e957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor (DENGELI VERÄ°)...\n",
            "ğŸ“Š Ä°ÅŸlenecek: 4,000 kayÄ±t\n",
            "â±ï¸  Tahmini sÃ¼re: ~20 dakika\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ã‡Ä±karÄ±m: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [39:18<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… TamamlandÄ±!\n",
            "  BaÅŸarÄ±lÄ±: 4,000\n",
            "  BaÅŸarÄ±sÄ±z: 0\n",
            "  BaÅŸarÄ± oranÄ±: 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ VERÄ° HAZIRLAMA"
      ],
      "metadata": {
        "id": "prepare"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(features_list)\n",
        "y = np.array(labels_list)\n",
        "\n",
        "print(f\"âœ… Dengeli veri hazÄ±r:\")\n",
        "print(f\"  Shape: {X.shape}\")\n",
        "\n",
        "print(f\"\\nğŸŒ¾ FÄ°NAL SINIF DAÄILIMI:\")\n",
        "print(\"=\"*60)\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "for crop, count in zip(unique, counts):\n",
        "    pct = count/len(y)*100\n",
        "    print(f\"  {crop:30s}: {count:5,} ({pct:5.1f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "imbalance = counts.max() / counts.min()\n",
        "print(f\"\\nâš–ï¸ Dengelilik: {imbalance:.2f}x\")\n",
        "\n",
        "# Class weight gerekli mi?\n",
        "use_class_weight = imbalance > 1.5\n",
        "print(f\"   Class weight: {'Evet' if use_class_weight else 'HayÄ±r (dengeli)'}\")\n",
        "\n",
        "# Label encoding\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“Š Veri bÃ¶lme:\")\n",
        "print(f\"  Train: {X_train.shape[0]:,}\")\n",
        "print(f\"  Test:  {X_test.shape[0]:,}\")"
      ],
      "metadata": {
        "id": "prepare_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053d62b7-de2d-466e-8326-da03f0f7dc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dengeli veri hazÄ±r:\n",
            "  Shape: (4000, 22)\n",
            "\n",
            "ğŸŒ¾ FÄ°NAL SINIF DAÄILIMI:\n",
            "============================================================\n",
            "  Lucerne/Medics                : 1,000 ( 25.0%)\n",
            "  Planted pastures (perennial)  : 1,000 ( 25.0%)\n",
            "  Wheat                         : 1,000 ( 25.0%)\n",
            "  Wine grapes                   : 1,000 ( 25.0%)\n",
            "============================================================\n",
            "\n",
            "âš–ï¸ Dengelilik: 1.00x\n",
            "   Class weight: HayÄ±r (dengeli)\n",
            "\n",
            "ğŸ“Š Veri bÃ¶lme:\n",
            "  Train: 3,200\n",
            "  Test:  800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸŒ² RANDOM FOREST (Dengeli Veri)"
      ],
      "metadata": {
        "id": "rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ğŸŒ² Random Forest (DENGELI VERÄ°)...\\n\")\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=30,\n",
        "    class_weight='balanced' if use_class_weight else None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_time = time.time() - start\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"\\nâœ… TamamlandÄ± ({rf_time:.2f}s)\")\n",
        "print(f\"\\nğŸ“Š Random Forest (DENGELI):\")\n",
        "print(f\"  Accuracy:  {rf_acc:.4f}\")\n",
        "print(f\"  F1-Score:  {rf_f1:.4f}\")"
      ],
      "metadata": {
        "id": "rf_train",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16203174-f8e4-4e3b-f26b-48309ce4bd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ² Random Forest (DENGELI VERÄ°)...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… TamamlandÄ± (2.10s)\n",
            "\n",
            "ğŸ“Š Random Forest (DENGELI):\n",
            "  Accuracy:  0.6075\n",
            "  F1-Score:  0.5994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸš€ XGBOOST (Dengeli Veri)"
      ],
      "metadata": {
        "id": "xgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"ğŸš€ XGBoost (DENGELI VERÄ°)...\\n\")\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "if use_class_weight:\n",
        "    from sklearn.utils.class_weight import compute_sample_weight\n",
        "    sample_weights = compute_sample_weight('balanced', y_train)\n",
        "    start = time.time()\n",
        "    xgb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "else:\n",
        "    start = time.time()\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_time = time.time() - start\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
        "xgb_f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "\n",
        "print(f\"\\nâœ… TamamlandÄ± ({xgb_time:.2f}s)\")\n",
        "print(f\"\\nğŸ“Š XGBoost (DENGELI):\")\n",
        "print(f\"  Accuracy:  {xgb_acc:.4f}\")\n",
        "print(f\"  F1-Score:  {xgb_f1:.4f}\")"
      ],
      "metadata": {
        "id": "xgb_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Š KARÅILAÅTIRMA: Dengesiz vs Dengeli"
      ],
      "metadata": {
        "id": "compare"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“Š KAPSAMLI KARÅILAÅTIRMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Dengesiz sonuÃ§lar (100 tile)\n",
        "imbalanced_rf = 0.76\n",
        "imbalanced_xgb = 0.76\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Strateji': ['Dengesiz (8,228)', 'Dengesiz (8,228)', 'Dengeli (~4,000)', 'Dengeli (~4,000)'],\n",
        "    'Model': ['Random Forest', 'XGBoost', 'Random Forest', 'XGBoost'],\n",
        "    'Accuracy': [imbalanced_rf, imbalanced_xgb, rf_acc, xgb_acc],\n",
        "    'F1-Score': [0.73, 0.75, rf_f1, xgb_f1]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison.to_string(index=False))\n",
        "\n",
        "# En iyi sonuÃ§\n",
        "best_idx = comparison['Accuracy'].idxmax()\n",
        "best = comparison.iloc[best_idx]\n",
        "\n",
        "print(f\"\\nğŸ† EN Ä°YÄ° SONUÃ‡:\")\n",
        "print(f\"  Strateji: {best['Strateji']}\")\n",
        "print(f\"  Model: {best['Model']}\")\n",
        "print(f\"  Accuracy: {best['Accuracy']:.4f}\")\n",
        "print(f\"  F1-Score: {best['F1-Score']:.4f}\")\n",
        "\n",
        "# Dengeli vs Dengesiz fark\n",
        "print(f\"\\nğŸ“ˆ DENGELI vs DENGESÄ°Z:\")\n",
        "rf_diff = (rf_acc - imbalanced_rf) * 100\n",
        "xgb_diff = (xgb_acc - imbalanced_xgb) * 100\n",
        "\n",
        "arrow_rf = \"ğŸ“ˆ\" if rf_diff > 0 else \"ğŸ“‰\"\n",
        "arrow_xgb = \"ğŸ“ˆ\" if xgb_diff > 0 else \"ğŸ“‰\"\n",
        "\n",
        "print(f\"  {arrow_rf} RF:  {imbalanced_rf:.1%} â†’ {rf_acc:.1%} ({rf_diff:+.1f}%)\")\n",
        "print(f\"  {arrow_xgb} XGB: {imbalanced_xgb:.1%} â†’ {xgb_acc:.1%} ({xgb_diff:+.1f}%)\")\n",
        "\n",
        "# Kaydet\n",
        "comparison.to_csv(TAB_DIR / 'balanced_vs_imbalanced_comparison.csv', index=False)\n",
        "print(f\"\\nğŸ’¾ KarÅŸÄ±laÅŸtÄ±rma kaydedildi\")"
      ],
      "metadata": {
        "id": "comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_, ax=axes[0])\n",
        "axes[0].set_title(f'RF - DENGELI (Acc: {rf_acc:.1%})')\n",
        "axes[0].set_ylabel('GerÃ§ek')\n",
        "axes[0].set_xlabel('Tahmin')\n",
        "\n",
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_, ax=axes[1])\n",
        "axes[1].set_title(f'XGB - DENGELI (Acc: {xgb_acc:.1%})')\n",
        "axes[1].set_ylabel('GerÃ§ek')\n",
        "axes[1].set_xlabel('Tahmin')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / 'confusion_matrices_BALANCED.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸŒ² RF - SÄ±nÄ±f BazÄ±nda (DENGELI):\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nğŸš€ XGB - SÄ±nÄ±f BazÄ±nda (DENGELI):\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nğŸ’¾ TÃ¼m sonuÃ§lar kaydedildi!\")"
      ],
      "metadata": {
        "id": "viz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}